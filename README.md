# ğŸ§­ Guide Dog AI
### Multimodal Navigation Assistant for the Visually Impaired

**Guide Dog AI** is a cross-platform mobile app (Android + iOS) that helps visually impaired users navigate safely using **real-time camera input** and **multimodal AI (Gemini)**.  
It provides **voice and haptic feedback** to describe surroundings, warn about obstacles, and guide users interactively along safe walking routes.

![Alt text](assets/img.png)

---

## ğŸŒŸ Features

### ğŸ‘ï¸ AI Scene Understanding
- Uses the phoneâ€™s camera and a **multimodal LLM** to interpret the environment in real-time.
- Describes scenes conversationally:
  > â€œYouâ€™re approaching a crosswalk with cars moving left to right.â€
- Detects obstacles (poles, walls, benches, pedestrians, etc.) and advises avoidance:
  > â€œObstacle ahead, move slightly left.â€

### ğŸ”Š Audio + Haptic Feedback
- Text-to-Speech (TTS) for natural voice guidance.
- Optional **vibration cues** for left/right turns or obstacle alerts.
- Configurable feedback sensitivity.

### ğŸ”’ Privacy by Design
- No video is stored â€” all camera data is processed transiently for inference.
---

## ğŸ§± Architecture Overview

```text
Camera Feed â”€â–¶ Frame Sampler (1â€“2 FPS)
               â”‚
               â–¼
        Multimodal LLM API
            (Gemini)
               â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â–¼                   â–¼
 Scene Description   Obstacle Warnings
     â”‚                   â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â–¼
   Voice + Haptic Feedback
